{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"currency_classification_notebook.ipynb","provenance":[{"file_id":"https://github.com/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part3.ipynb","timestamp":1569738152377}],"collapsed_sections":["jTEzoMx6CasV","tt15y6IS2pBo"],"toc_visible":true},"kernelspec":{"display_name":"Python 2","name":"python2"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jTEzoMx6CasV"},"source":["#### Copyright 2018 Google LLC."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IhmPj1VVCfWb","colab":{}},"source":["# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dI5rmt4UBwXs"},"source":["## Feature Extraction Using a Pretrained Model\n","\n","One thing that is commonly done in computer vision is to take a model trained on a very large dataset, run it on your own, smaller dataset, and extract the intermediate representations (features) that the model generates. These representations are frequently informative for your own computer vision task, even though the task may be quite different from the problem that the original model was trained on. This versatility and repurposability of convnets is one of the most interesting aspects of deep learning.\n","\n","In our case, we will use the [Inception V3 model](https://arxiv.org/abs/1512.00567) developed at Google, and pre-trained on [ImageNet](http://image-net.org/), a large dataset of web images (1.4M images and 1000 classes). This is a powerful model; let's see what the features that it has learned can do for our cat vs. dog problem.\n","\n","First, we need to pick which intermediate layer of Inception V3 we will use for feature extraction. A common practice is to use the output of the very last layer before the `Flatten` operation, the so-called \"bottleneck layer.\" The reasoning here is that the following fully connected layers will be too specialized for the task the network was trained on, and thus the features learned by these layers won't be very useful for a new task. The bottleneck features, however, retain much generality.\n","\n","Let's instantiate an Inception V3 model preloaded with weights trained on ImageNet:\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1xJZ5glPPCRz","outputId":"0f7f944b-d9f3-44d2-98f1-ab010a135720","executionInfo":{"status":"ok","timestamp":1574051155787,"user_tz":-330,"elapsed":2703,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["import os\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VaXLMtYiF0t9"},"source":["Now let's download the weights:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KMrbllgAFipZ","outputId":"cb088986-968b-4739-a32c-edacc14c1dcb","executionInfo":{"status":"ok","timestamp":1574051161827,"user_tz":-330,"elapsed":5325,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["!wget --no-check-certificate \\\n","    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n","    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2019-11-18 04:22:49--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 2404:6800:4008:c01::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 87910968 (84M) [application/x-hdf]\n","Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n","\n","\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep  33%[=====>              ]  28.06M   140MB/s               \r        /tmp/incept  66%[============>       ]  56.01M   114MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M   137MB/s    in 0.6s    \n","\n","2019-11-18 04:22:50 (137 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"My-UTKdpQlln","colab_type":"text"},"source":["By specifying the include_top=False argument, we load a network that doesn't include the classification layers at the top—ideal for feature extraction. input_shpe can be used only when include-top=false.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UnRiGBfOF8rq","outputId":"2202339a-ffc8-4497-a117-d80a344cb75a","executionInfo":{"status":"ok","timestamp":1574051178209,"user_tz":-330,"elapsed":14074,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["from tensorflow.keras.applications.inception_v3 import InceptionV3\n","\n","local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","pre_trained_model = InceptionV3(\n","    input_shape=(300, 150, 3), include_top=False, weights=None)\n","pre_trained_model.load_weights(local_weights_file)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W1118 04:22:55.926901 140112643757952 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CFxrqTuJee5m"},"source":["Let's make the model non-trainable, since we will only use it for feature extraction; we won't update the weights of the pretrained model during training.\n","\n","\"freeze\" a layer means to exclude it from training, i.e. its weights will never be updated. \n","\n","You can pass a trainable argument (boolean) to a layer constructor to set a layer to be non-trainable:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"a38rB3lyedcB","colab":{}},"source":["for layer in pre_trained_model.layers:\n","  layer.trainable = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XGBGDiOAepnO"},"source":["The layer we will use for feature extraction in Inception v3 is called `mixed7`. It is not the bottleneck of the network, but we are using it to keep a sufficiently large feature map (7x7 in this case). (Using the bottleneck layer would have resulting in a 3x3 feature map, which is a bit small.) Let's get the output from `mixed7`:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Cj4rXshqbQlS","outputId":"7412ba18-4875-4f30-cde4-17c22a0c89ed","executionInfo":{"status":"ok","timestamp":1574051185686,"user_tz":-330,"elapsed":1586,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["last_layer = pre_trained_model.get_layer('mixed7')\n","print 'last layer output shape:', last_layer.output_shape\n","last_output = last_layer.output"],"execution_count":5,"outputs":[{"output_type":"stream","text":["last layer output shape: (None, 17, 7, 768)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XxHk6XQLeUWh"},"source":["Now let's stick a fully connected classifier on top of `last_output`:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BMXb913pbvFg","outputId":"f978fae8-a52f-4ed2-848f-f1a97759fdc9","executionInfo":{"status":"ok","timestamp":1574051190866,"user_tz":-330,"elapsed":1535,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["from tensorflow.keras.optimizers import RMSprop\n","\n","# Flatten the output layer to 1 dimension\n","x = layers.Flatten()(last_output)\n","# Add a fully connected layer with 1,024 hidden units and ReLU activation\n","x = layers.Dense(1024, activation='relu')(x)\n","# Add a dropout rate of 0.2\n","x = layers.Dropout(0.2)(x)\n","# Add a final sigmoid layer for classification\n","x = layers.Dense(1, activation='sigmoid')(x)\n","\n","# Configure and compile the model\n","model = Model(pre_trained_model.input, x)\n","model.compile(loss='binary_crossentropy',\n","              optimizer=RMSprop(lr=0.0001),\n","              metrics=['acc'])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["W1118 04:23:21.179666 140112643757952 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"7a1TqZTntuzi","colab_type":"code","outputId":"710246f6-ce4e-4375-f48f-0ccce01f4e7b","executionInfo":{"status":"ok","timestamp":1574051230058,"user_tz":-330,"elapsed":36800,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Fl9XXARuV_eg","outputId":"66a1af8e-e33f-4db0-a9f9-b7bfb26f6948","executionInfo":{"status":"ok","timestamp":1574051263719,"user_tz":-330,"elapsed":30238,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import os\n","import zipfile\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# local_zip = '/tmp/cats_and_dogs_filtered.zip'\n","# zip_ref = zipfile.ZipFile(local_zip, 'r')\n","# zip_ref.extractall('/tmp')\n","# zip_ref.close()\n","\n","\n","\n","# Define our example directories and files\n","base_dir = '/content/drive/My Drive/Colab Notebooks/currency_images/'\n","train_dir = os.path.join(base_dir, 'train2000')\n","validation_dir = os.path.join(base_dir, 'test2000')\n","\n","# Directory with our training fake pictures\n","train_fake_dir = os.path.join(train_dir, 'fake_2000')\n","\n","# Directory with our training orignal pictures\n","train_orig_dir = os.path.join(train_dir, 'original_2000')\n","\n","# Directory with our validation fake pictures\n","validation_fake_dir = os.path.join(train_dir, 'fake_2000','TrainFake')\n","\n","# Directory with our validation original pictures\n","validation_orig_dir = os.path.join(train_dir, 'original_2000','output')\n","\n","train_fake_fnames = os.listdir(train_fake_dir)\n","train_orig_fnames = os.listdir(train_orig_dir)\n","\n","# Add our data-augmentation parameters to ImageDataGenerator\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","# Note that the validation data should not be augmented!\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","        train_dir, # This is the source directory for training images\n","        target_size=(300, 150),  # All images will be resized to 150x150\n","        batch_size=20,\n","        # Since we use binary_crossentropy loss, we need binary labels\n","        class_mode='binary')\n","\n","# Flow validation images in batches of 20 using test_datagen generator\n","validation_generator = test_datagen.flow_from_directory(\n","        validation_dir,\n","        target_size=(300, 150),\n","        batch_size=20,\n","        class_mode='binary')\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Found 12587 images belonging to 2 classes.\n","Found 10 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qEC1AL7iVRLz"},"source":["Finally, let's train the model using the features we extracted. We'll train on all 2000 images available, for 3 epochs, and validate on all  test images."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Blhq2MAUeyGA","outputId":"85cb2f9f-4192-4933-d6a8-097cc7c6b7bb","executionInfo":{"status":"error","timestamp":1574010446686,"user_tz":-330,"elapsed":2730,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["history = model.fit_generator(\n","      train_generator,\n","      steps_per_epoch=100,\n","      epochs=100,\n","      validation_data=validation_generator,\n","      validation_steps=50,\n","      verbose=1)\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-1-db149e706dec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit_generator(\n\u001b[0m\u001b[1;32m      2\u001b[0m       \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","metadata":{"id":"rMnTIw6lxZ1_","colab_type":"code","colab":{}},"source":["model.save(\"/content/drive/My Drive/Colab Notebooks/model_fake_original_detectionimages_50epoch.h5\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F6fBPepczW7j","colab_type":"code","outputId":"70092031-b911-4b32-bb6f-f403007692c5","executionInfo":{"status":"ok","timestamp":1574051303873,"user_tz":-330,"elapsed":22395,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":190}},"source":["\n","from tensorflow.keras.models import load_model\n","#from keras.models import load_model\n","import cv2\n","import numpy as np\n","\n","model_new = load_model('/content/drive/My Drive/Colab Notebooks/model_fake_original_10000images_50epoch.h5')\n","\n","#model_new.compile(loss='binary_crossentropy',\n","#               optimizer='rmsprop',\n","#               metrics=['accuracy'])\n","\n","img = cv2.imread('/content/drive/My Drive/Colab Notebooks/currency_images/train2000/original_2000/output/real20.jpg')\n","#img = cv2.imread('/content/drive/My Drive/Colab Notebooks/currency_images/train2000/fake_train/fake5.jpg')\n","\n","\n","img = cv2.resize(img,(300,150))\n","img = np.reshape(img,[1,300,150,3])\n","\n","classes = model_new.predict(img)\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["W1118 04:24:54.034998 140112643757952 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W1118 04:24:54.036967 140112643757952 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W1118 04:24:54.046946 140112643757952 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ZVJ6RBL44ivb","colab_type":"code","outputId":"af5e28a2-6cbc-4857-b0cf-966a2ed8b030","executionInfo":{"status":"ok","timestamp":1572767114633,"user_tz":-330,"elapsed":2799544,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for file_name in os.listdir(\"/content/drive/My Drive/Colab Notebooks/currency_images/train2000/fake_2000/output/\"):\n","  img = cv2.imread('/content/drive/My Drive/Colab Notebooks/currency_images/train2000/fake_2000/output/' + file_name)\n","  img = cv2.resize(img,(300,150))\n","  img = np.reshape(img,[1,300,150,3])\n","  classes = model_new.predict(img)\n","  for item in classes[:10]:\n","    if (item[0]>.799):\n","      print(\"Fake\")\n","    else:\n","      print(\"Real\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Fake\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Fake\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Fake\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n","Real\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sBTvQyDJyK1X","colab_type":"text"},"source":["function"]},{"cell_type":"code","metadata":{"id":"Xn-qLFlW3bqr","colab_type":"code","outputId":"6cac0fdc-8434-4766-ac52-9f04d2fb8ac4","executionInfo":{"status":"ok","timestamp":1572767123558,"user_tz":-330,"elapsed":1282,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rAoYBP2ME9AO","colab_type":"code","colab":{}},"source":["from tensorflow.keras.models import load_model\n","#from keras.models import load_model\n","import cv2\n","import numpy as np \n","model_new = load_model('/content/drive/My Drive/Colab Notebooks/model_fake_original_10000images_50epoch.h5')\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SGVVNHyNyIyu","colab_type":"code","outputId":"f31ed0d4-c505-43d0-d36b-2b2b22919136","executionInfo":{"status":"ok","timestamp":1572843091941,"user_tz":-330,"elapsed":4710,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#image_path ='/content/drive/My Drive/Colab Notebooks/currency_images/train2000/original_2000/output/real3.jpg'\n","image_path ='/content/drive/My Drive/Colab Notebooks/currency_images/train2000/fake_2000/output/fake25.jpg'\n","#img = cv2.imread('/content/drive/My Drive/Colab Notebooks/currency_images/train2000/fake_train/fake5.jpg')\n","#img = cv2.resize(img,(300,150))\n","#img = np.reshape(img,[1,300,150,3])\n","#classes = model_new.predict(img)\n","\n","def funtest(image_path):\n","  #img = cv2.imread('/content/drive/My Drive/Colab Notebooks/currency_images/train2000/original_2000/output/fake50.jpg')\n","  img = cv2.imread(image_path)\n","  img = cv2.resize(img,(300,150))\n","  img = np.reshape(img,[1,300,150,3])\n","  classes = model_new.predict(img)\n","  for item in classes[:10]:\n","    if (item[0]>.799):\n","      print(\"Fake\")\n","    else:\n","      print(\"Real\")\n","funtest(image_path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Real\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lRjyAkE62aOG"},"source":["You can see that we reach a validation accuracy of 88–90% \n","\n","\n","very quickly. This is much better than the small model we trained from scratch."]},{"cell_type":"code","metadata":{"id":"uOwcw1NYUTVB","colab_type":"code","outputId":"00ddd4b9-3d24-4bf1-e26f-e319e9a55bf2","executionInfo":{"status":"ok","timestamp":1572768668847,"user_tz":-330,"elapsed":7561,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["pip install flask-ngrok"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting flask-ngrok\n","  Downloading https://files.pythonhosted.org/packages/1e/41/43e7bdcc4dac453b927feff5e0c9e30f8d34ef46c19fa320256893926893/flask-ngrok-0.0.25.tar.gz\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python2.7/dist-packages (from flask-ngrok) (0.12.2)\n","Requirement already satisfied: requests in /usr/local/lib/python2.7/dist-packages (from flask-ngrok) (2.21.0)\n","Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python2.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n","Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python2.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.10.1)\n","Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python2.7/dist-packages (from Flask>=0.8->flask-ngrok) (0.15.5)\n","Requirement already satisfied: click>=2.0 in /usr/local/lib/python2.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.0)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests->flask-ngrok) (2019.6.16)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests->flask-ngrok) (2.8)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python2.7/dist-packages (from Jinja2>=2.4->Flask>=0.8->flask-ngrok) (1.1.1)\n","Building wheels for collected packages: flask-ngrok\n","  Building wheel for flask-ngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for flask-ngrok: filename=flask_ngrok-0.0.25-cp27-none-any.whl size=3043 sha256=074010b9f90fe5b9a3aef3f2c6b941741b422f0bd3c7c3e85540764ebd14f396\n","  Stored in directory: /root/.cache/pip/wheels/4b/52/9f/3f85c132d06485491eb5572de5eb6be2c7e3559409073ee78c\n","Successfully built flask-ngrok\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yednoPMBRqRe","colab_type":"code","outputId":"32fec5ec-e731-40c5-8aaf-c16d7419658f","executionInfo":{"status":"ok","timestamp":1572768071966,"user_tz":-330,"elapsed":12761,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":258}},"source":["!pip install flask==0.12.2"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting flask==0.12.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/32/e3597cb19ffffe724ad4bf0beca4153419918e7fa4ba6a34b04ee4da3371/Flask-0.12.2-py2.py3-none-any.whl (83kB)\n","\r\u001b[K     |████                            | 10kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 30kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 40kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 51kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 71kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 81kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 5.2MB/s \n","\u001b[?25hRequirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python2.7/dist-packages (from flask==0.12.2) (1.1.0)\n","Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python2.7/dist-packages (from flask==0.12.2) (2.10.1)\n","Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python2.7/dist-packages (from flask==0.12.2) (0.15.5)\n","Requirement already satisfied: click>=2.0 in /usr/local/lib/python2.7/dist-packages (from flask==0.12.2) (7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python2.7/dist-packages (from Jinja2>=2.4->flask==0.12.2) (1.1.1)\n","Installing collected packages: flask\n","  Found existing installation: Flask 1.1.1\n","    Uninstalling Flask-1.1.1:\n","      Successfully uninstalled Flask-1.1.1\n","Successfully installed flask-0.12.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YqE9TpopTbcL","colab_type":"code","outputId":"9927653d-3b3f-4a98-d7f1-e62b6ad68fa5","executionInfo":{"status":"ok","timestamp":1572770952930,"user_tz":-330,"elapsed":1499637,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["from flask import Flask\n","#from flask_ngrok import run_with_ngrok\n","app = Flask(__name__)\n","#run_with_ngrok(app)  # Start ngrok when app is run\n","import socket\n","print(socket.gethostbyname(socket.getfqdn(socket.gethostname())))\n","\n","@app.route(\"/\")\n","def hello():\n","   return \"Hello World!\"\n","\n","if __name__ == '__main__':\n","   app.run(host='0.0.0.0')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["I1103 08:20:57.987487 139669717890944 _internal.py:122]  * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n"],"name":"stderr"},{"output_type":"stream","text":["172.28.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NdoBYujUNIof","colab_type":"code","outputId":"670459ec-7700-45be-c8db-2305ed89d434","executionInfo":{"status":"ok","timestamp":1572154963913,"user_tz":-330,"elapsed":2032,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tt15y6IS2pBo"},"source":["## Further Improving Accuracy with Fine-Tuning\n","\n","In our feature-extraction experiment, we only tried adding two classification layers on top of an Inception V3 layer. The weights of the pretrained network were not updated during training. One way to increase performance even further is to \"fine-tune\" the weights of the top layers of the pretrained model alongside the training of the top-level classifier. A couple of important notes on fine-tuning:\n","\n","- **Fine-tuning should only be attempted *after* you have trained the top-level classifier with the pretrained model set to non-trainable**. If you add a randomly initialized classifier on top of a pretrained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier), and your pretrained model will just forget everything it has learned.\n","- Additionally, we **fine-tune only the *top layers* of the pre-trained model** rather than all layers of the pretrained model because, in a convnet, the higher up a layer is, the more specialized it is. The first few layers in a convnet learn very simple and generic features, which generalize to almost all types of images. But as you go higher up, the features are increasingly specific to the dataset that the model is trained on. The goal of fine-tuning is to adapt these specialized features to work with the new dataset.\n","\n","All we need to do to implement fine-tuning is to set the top layers of Inception V3 to be trainable, recompile the model (necessary for these changes to take effect), and resume training. Let's unfreeze all layers belonging to the `mixed7` module—i.e., all layers found after `mixed6`—and recompile the model:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_l_J4S0Z2rgg","colab":{}},"source":["from tensorflow.keras.optimizers import SGD\n","\n","unfreeze = False\n","\n","# Unfreeze all models after \"mixed6\"\n","for layer in pre_trained_model.layers:\n","  if unfreeze:\n","    layer.trainable = True\n","  if layer.name == 'mixed6':\n","    unfreeze = True\n","\n","# As an optimizer, here we will use SGD \n","# with a very low learning rate (0.00001)\n","model.compile(loss='binary_crossentropy',\n","              optimizer=SGD(\n","                  lr=0.00001, \n","                  momentum=0.9),\n","              metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zE37ARlqY9da"},"source":["Now let's retrain the model. We'll train on all 2000 images available, for 50 epochs, and validate on all 1,000 test images. (This may take 15-20 minutes to run.)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"o_GgDGG4Y_hJ","colab":{}},"source":["history = model.fit_generator(\n","      train_generator,\n","      steps_per_epoch=100,\n","      epochs=50,\n","      validation_data=validation_generator,\n","      validation_steps=50,\n","      verbose=2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3EPGn58ofwq5"},"source":["We are seeing a nice improvement, with the validation loss going from ~1.7 down to ~1.2, and accuracy going from 88% to 92%. That's a 4.5% relative improvement in accuracy.\n","\n","Let's plot the training and validation loss and accuracy to show it conclusively:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1FtxcKjJfxL9","colab":{}},"source":["%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","# Retrieve a list of accuracy results on training and test data\n","# sets for each training epoch\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","\n","# Retrieve a list of list results on training and test data\n","# sets for each training epoch\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","# Get number of epochs\n","epochs = range(len(acc))\n","\n","# Plot training and validation accuracy per epoch\n","plt.plot(epochs, acc)\n","plt.plot(epochs, val_acc)\n","plt.title('Training and validation accuracy')\n","\n","plt.figure()\n","\n","# Plot training and validation loss per epoch\n","plt.plot(epochs, loss)\n","plt.plot(epochs, val_loss)\n","plt.title('Training and validation loss')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"X-fUIeizakjE"},"source":["Congratulations! Using feature extraction and fine-tuning, you've built an image classification model that can identify cats vs. dogs in images with over 90% accuracy."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"x_ANwJCnx7w-"},"source":["## Clean Up\n","\n","Run the following cell to terminate the kernel and free memory resources:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-hUmyohAyBzh","colab":{}},"source":["import os, signal\n","os.kill(os.getpid(), signal.SIGKILL)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p_912m-8kY6r","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"2ifN7yGmkZou","colab_type":"code","outputId":"dd71e5fe-2f5a-4d61-d723-321d33eeaa5e","executionInfo":{"status":"ok","timestamp":1573376883191,"user_tz":-330,"elapsed":1773,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["import socket\n","print(socket.gethostbyname(socket.getfqdn(socket.gethostname())))\n","\n","from flask import Flask\n","app = Flask(__name__)\n","\n","@app.route(\"/\")\n","def hello():\n","    return \"Hello World!\"\n","\n","import threading\n","threading.Thread(target=app.run, kwargs={'host':'0.0.0.0','port':80}).start() "],"execution_count":0,"outputs":[{"output_type":"stream","text":["172.28.0.2\n"," * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","   WARNING: This is a development server. Do not use it in a production deployment.\n","   Use a production WSGI server instead.\n"," * Debug mode: off\n"],"name":"stdout"},{"output_type":"stream","text":[" * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"jIB5hpvjka-z","colab_type":"code","outputId":"4222e74e-332a-43f7-95c7-8e60d40741cb","executionInfo":{"status":"ok","timestamp":1573377365598,"user_tz":-330,"elapsed":6686,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["!pip install flask-ngrok\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting flask-ngrok\n","  Downloading https://files.pythonhosted.org/packages/1e/41/43e7bdcc4dac453b927feff5e0c9e30f8d34ef46c19fa320256893926893/flask-ngrok-0.0.25.tar.gz\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python2.7/dist-packages (from flask-ngrok) (1.1.1)\n","Requirement already satisfied: requests in /usr/local/lib/python2.7/dist-packages (from flask-ngrok) (2.21.0)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python2.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.0)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python2.7/dist-packages (from Flask>=0.8->flask-ngrok) (0.15.5)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python2.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python2.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.10.1)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests->flask-ngrok) (2019.6.16)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests->flask-ngrok) (2.8)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python2.7/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n","Building wheels for collected packages: flask-ngrok\n","  Building wheel for flask-ngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for flask-ngrok: filename=flask_ngrok-0.0.25-cp27-none-any.whl size=3043 sha256=571fcbf3a066c785639dc7e984c0bbc0ba4c57fc2b18d933202c0f61ee571ca1\n","  Stored in directory: /root/.cache/pip/wheels/4b/52/9f/3f85c132d06485491eb5572de5eb6be2c7e3559409073ee78c\n","Successfully built flask-ngrok\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xYZT8RPCmTtm","colab_type":"code","outputId":"d7b99b31-4194-4287-8823-ceee69186295","executionInfo":{"status":"error","timestamp":1573377484697,"user_tz":-330,"elapsed":1127,"user":{"displayName":"Reshma 0997","photoUrl":"","userId":"09151279691664068757"}},"colab":{"base_uri":"https://localhost:8080/","height":130}},"source":[""],"execution_count":0,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"/usr/local/lib/python2.7/dist-packages/flask_ngrok.py\"\u001b[0;36m, line \u001b[0;32m27\u001b[0m\n\u001b[0;31m    raise Exception(f\"{system} is not supported\")\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"ZtYAHlv8myKQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}